{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naiveBayes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "tQyOA04iTGLw",
        "colab_type": "code",
        "outputId": "84a7edfb-abdf-4029-bf11-44b549404d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets,model_selection\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.util import ngrams\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('perluniprops')\n",
        "from nltk.tokenize.moses import MosesDetokenizer\n",
        "import sklearn\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn import model_selection,metrics,naive_bayes,pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "IU7vq3PjNCT4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Format the files so we will extract info easier from them"
      ]
    },
    {
      "metadata": {
        "id": "B3TUThKuAnp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "allFiles=[]\n",
        "for f in os.listdir('.'):\n",
        "  if(os.path.isfile(f) and f[0]!='.'):\n",
        "    new=True\n",
        "    for i in range(len(allFiles)):\n",
        "      if(allFiles[i][0][:-5]==f[:-5]):\n",
        "        new=False\n",
        "        allFiles[i].append(f)\n",
        "    if(new):\n",
        "      allFiles.append([f])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3oTvvNAlJdmx",
        "colab_type": "code",
        "outputId": "259ac00d-1908-47ff-fb77-c90fe86f7ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(allFiles))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BbyWGpZtFK01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "sentences=[]\n",
        "for i in range(len(allFiles)):\n",
        "  sentences=[]\n",
        "  for j in range(len(allFiles[i])):\n",
        "    sentences.append([])\n",
        "    filepath = allFiles[i][j]\n",
        "    with open(filepath) as fp:  \n",
        "      line = fp.readline()\n",
        "      while line:\n",
        "        sentences[j].append(line)\n",
        "        line = fp.readline()\n",
        "  for k in range(len(sentences[0])):\n",
        "    if(sentences[0][k][0]!='#'):\n",
        "      term1=sentences[0][k][:4]\n",
        "      term2=sentences[1][k][:4]\n",
        "      term3=sentences[2][k][:4]\n",
        "      if(term1==term2 or term1==term3):\n",
        "        X.append(sentences[0][k][4:])\n",
        "        #print(term1,sentences[0][k][4:])\n",
        "        Y.append(term1)\n",
        "      elif(term2==term3):\n",
        "        X.append(sentences[0][k][4:])\n",
        "        #print(term2,sentences[0][k][4:])\n",
        "        Y.append(term2)\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, random_state = 22,stratify=Y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hdi-w-aWHjdn",
        "colab_type": "code",
        "outputId": "b11141e5-fa00-4f95-a7a2-21371312ef43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(X),len(Y))\n",
        "print(len(x_train),len(y_train))\n",
        "print(len(x_test),len(y_test))\n",
        "print(len(x_test[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1035 1035\n",
            "776 776\n",
            "259 259\n",
            "77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oqi-tigg9lDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prossesing (lemma,stopword,stemming,sentences):\n",
        "  for i in range(len(sentences)):\n",
        "    detokenizer = MosesDetokenizer()\n",
        "    token_sentences=nltk.word_tokenize(sentences[i])\n",
        "    if(stopword):\n",
        "      token_sentences=[word for word in token_sentences if word not in stopwords.words('english')]\n",
        "    if(stemming):\n",
        "      stemmer = SnowballStemmer(\"english\",ignore_stopwords=True)\n",
        "      token_sentences=[stemmer.stem(word) for word in token_sentences]\n",
        "    if(lemma):\n",
        "      p=1\n",
        "    sentences[i]=detokenizer.detokenize(token_sentences, return_str=True)\n",
        "  return sentences\n",
        "\n",
        "\n",
        "x_train_prossesed = prossesing(lemma=False,stopword=True,stemming=True,sentences=x_train)\n",
        "x_test_prossesed = prossesing(lemma=False,stopword=False,stemming=True,sentences=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VBc0swB-CG7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(x_train)):\n",
        "  print(len(x_train_prossesed[i]),len(x_train[i]),x_train[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hn2g0QbD6gLg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "multiNB_pipe = pipeline.Pipeline([\n",
        "     ('tfidf', TfidfVectorizer()),\n",
        "     ('clf', naive_bayes.MultinomialNB())\n",
        "])\n",
        "\n",
        "# Parameters to explore for Multinomial Naive Bayes Classifier\n",
        "params = {\n",
        "    'tfidf__max_features': (5000, 10000, 2500),\n",
        "    'tfidf__ngram_range': ((1, 1), (2, 2)),\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'clf__alpha': (0.05, 0.01,0.1),\n",
        "}\n",
        "\n",
        "# Find the best parameters for both feature extraction and classifier\n",
        "grid_search_MNB = GridSearchCV(multiNB_pipe, params, cv=3, n_jobs=-1, verbose=1, return_train_score=True)\n",
        "\n",
        "# Fit the data into the GridSearch\n",
        "scores = cross_val_score(grid_search_MNB, x_train_prossesed, y_train, cv=5)\n",
        "grid_search_MNB.fit(x_train_prossesed, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqRN0DehN5xY",
        "colab_type": "code",
        "outputId": "3cbde2dc-18ad-4ebb-e745-cb94cfbb56b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "print(grid_search_MNB.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.70 (+/- 0.06)\n",
            "Pipeline(memory=None,\n",
            "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
            "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
            "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...rue,\n",
            "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tUOq7k6vFfjX",
        "colab_type": "code",
        "outputId": "9ad17772-7e72-4a67-fb54-088c15f58348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "best_pipe_MNB = grid_search_MNB.best_estimator_\n",
        "print(grid_search_MNB.best_score_)\n",
        "\n",
        "y_predicted=best_pipe_MNB.predict(x_test)\n",
        "prec = metrics.precision_score(y_test,y_predicted.tolist(),average='weighted')\n",
        "rec = metrics.recall_score(y_test,y_predicted,average='weighted')\n",
        "f1 = metrics.f1_score(y_test,y_predicted,average='weighted')\n",
        "print('Results: \\n')\n",
        "print('Precision: {}'.format(prec))\n",
        "print('Recall: {}'.format(rec))\n",
        "print('F1 Score: {}'.format(f1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7061855670103093\n",
            "['MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'AIMX', 'MISC', 'OWNX', 'CONT', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'AIMX', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'AIMX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'CONT', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'AIMX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC']\n",
            "['OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'AIMX', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'OWNX', 'MISC', 'CONT', 'OWNX', 'OWNX', 'MISC', 'AIMX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'AIMX', 'CONT', 'CONT', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'BASE', 'CONT', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'AIMX', 'MISC', 'MISC', 'AIMX', 'OWNX', 'MISC', 'MISC', 'CONT', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'MISC', 'AIMX', 'MISC', 'AIMX', 'OWNX', 'CONT', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'OWNX', 'AIMX', 'BASE', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'MISC', 'OWNX', 'CONT', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'CONT', 'MISC', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'CONT', 'OWNX', 'AIMX', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'BASE', 'MISC', 'MISC', 'OWNX', 'OWNX', 'OWNX', 'OWNX', 'AIMX', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'AIMX', 'MISC', 'MISC', 'OWNX', 'OWNX', 'CONT', 'MISC', 'MISC', 'OWNX', 'MISC', 'AIMX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'OWNX', 'AIMX', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'CONT', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'OWNX', 'AIMX', 'MISC', 'MISC', 'AIMX', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'AIMX', 'MISC', 'MISC', 'MISC', 'BASE', 'OWNX', 'BASE', 'OWNX', 'OWNX', 'MISC', 'MISC', 'MISC', 'OWNX', 'MISC', 'MISC', 'MISC']\n",
            "Results: \n",
            "\n",
            "Precision: 0.6833976833976834\n",
            "Recall: 0.6833976833976834\n",
            "F1 Score: 0.6415573601872986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "C1cZx0KF6-tM",
        "colab_type": "code",
        "outputId": "6b886ff0-51f2-48d7-a1ed-38de6b9a9b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "LogisticReg_pipe = pipeline.Pipeline([\n",
        "     ('tfidf', TfidfVectorizer()),\n",
        "     ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Parameters to explore for Multinomial Naive Bayes Classifier\n",
        "params = {\n",
        "    'tfidf__max_features': (5000, 10000, 2500),\n",
        "    'tfidf__ngram_range': ((1, 1), (2, 2)),\n",
        "    'tfidf__use_idf': (True, False),\n",
        "}\n",
        "\n",
        "# Find the best parameters for both feature extraction and classifier\n",
        "grid_search_LR = GridSearchCV(LogisticReg_pipe, params, cv=3, n_jobs=-1, verbose=1, return_train_score=True)\n",
        "\n",
        "# Fit the data into the GridSearch\n",
        "grid_search_LR.fit(x_train_prossesed, y_train)\n",
        "best_pipe_LR=grid_search_LR.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    1.3s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GAMuWcHN-XW0",
        "colab_type": "code",
        "outputId": "bad05af2-686f-4230-e398-952f8386e2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "best_pipe_LR = grid_search_LR.best_estimator_\n",
        "print(grid_search_LR.best_score_)\n",
        "\n",
        "y_predicted=best_pipe_LR.predict(x_test_prossesed)\n",
        "\n",
        "count=0\n",
        "for i in range(len(y_test)):\n",
        "  if(y_predicted[i]==y_test[i]):\n",
        "    count=count+1\n",
        "print(count/len(y_test))\n",
        "#print(y_predicted.tolist())\n",
        "#print(y_test)\n",
        "\n",
        "prec = metrics.precision_score(y_test,y_predicted,average='weighted')\n",
        "rec = metrics.recall_score(y_test,y_predicted,average='weighted')\n",
        "f1 = metrics.f1_score(y_test,y_predicted,average='weighted')\n",
        "print('Results: \\n')\n",
        "print('Precision: {}'.format(prec))\n",
        "print('Recall: {}'.format(rec))\n",
        "print('F1 Score: {}'.format(f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6469072164948454\n",
            "0.694980694980695\n",
            "Results: \n",
            "\n",
            "Precision: 0.623760852460404\n",
            "Recall: 0.694980694980695\n",
            "F1 Score: 0.626595235921303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}