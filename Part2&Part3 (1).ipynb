{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part2&Part3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DcBzidhyFb9V",
        "colab_type": "code",
        "outputId": "bf0ae047-dc1f-4e02-f883-d87a1f8cc008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/mydrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BHvvcsBihLra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import gensim.models.ldamulticore\n",
        "import os\n",
        "from sklearn import model_selection\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Add\n",
        "from keras.layers import Average\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import AveragePooling1D\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras import regularizers\n",
        "from keras.backend import mean\n",
        "from keras.backend import sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QYrbvkkIE_J-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Part 2"
      ]
    },
    {
      "metadata": {
        "id": "MbEn9D-4FA9K",
        "colab_type": "code",
        "outputId": "17f45135-f7a6-4483-9f0a-65c61a6f5e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "path=\"mydrive/My Drive/labeled_articles/\"\n",
        "#load the files from the drive \n",
        "allFiles=[]\n",
        "#every element of list allFiles contains the same text 3 times from every evaluator\n",
        "for f in os.listdir(path):\n",
        "  new=True\n",
        "  for i in range(len(allFiles)):\n",
        "    if(allFiles[i][0][:-5]==f[:-5]):\n",
        "      new=False\n",
        "      allFiles[i].append(f)\n",
        "  if(new):\n",
        "    allFiles.append([f])\n",
        "X=[]\n",
        "Y=[]\n",
        "sentences=[]\n",
        "for i in range(len(allFiles)):\n",
        "  sentences=[]\n",
        "  for j in range(len(allFiles[i])):\n",
        "    sentences.append([])\n",
        "    filepath = path+allFiles[i][j]\n",
        "    with open(filepath) as fp:  \n",
        "      line = fp.readline()\n",
        "      while line:\n",
        "        sentences[j].append(line)\n",
        "        line = fp.readline()\n",
        "  #sentences contain 3 lists,every element of those lists contain a sentence from different evaluators\n",
        "  for k in range(len(sentences[0])):\n",
        "    #ignore comments\n",
        "    if(sentences[0][k][0]!='#'):\n",
        "      #for each sentence we extract the class from the 3 different evaluators\n",
        "      term1=sentences[0][k][:4]\n",
        "      term2=sentences[1][k][:4]\n",
        "      term3=sentences[2][k][:4]\n",
        "      #if 2 evaluators agree for the class of a sentence we accept it,otherwise we ignore the sentence\n",
        "      if(term1==term2 or term1==term3):\n",
        "        X.append(sentences[0][k][4:])\n",
        "        Y.append(term1)\n",
        "      elif(term2==term3):\n",
        "        X.append(sentences[0][k][4:])\n",
        "        Y.append(term2)\n",
        "trainData=[]\n",
        "\n",
        "def readFiles(path,docs):\n",
        "  count=0\n",
        "  for f in os.listdir(path):\n",
        "    filepath=path+f\n",
        "    with open(filepath) as fp:\n",
        "      count=count+1\n",
        "      docs.append(fp.read())\n",
        "      if(count==100):\n",
        "        break\n",
        "  return docs\n",
        "print(len(X))\n",
        "X=readFiles(\"mydrive/My Drive/unlabeled_articles/arxiv_unlabeled/\",X)\n",
        "X=readFiles(\"mydrive/My Drive/unlabeled_articles/jdm_unlabeled/\",X)\n",
        "X=readFiles(\"mydrive/My Drive/unlabeled_articles/plos_unlabeled/\",X)\n",
        "print(len(X))\n",
        "for i in range(len(X)):\n",
        "  Line=remove_stopwords(X[i])\n",
        "  trainData.append(gensim.utils.simple_preprocess(Line))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1035\n",
            "1335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "61dhhAZAG6lz",
        "colab_type": "code",
        "outputId": "fa0fba9a-ac3b-4637-8c3e-c5e8162b5c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "firstModel = gensim.models.Word2Vec(\n",
        "        trainData,\n",
        "        size=100,\n",
        "        window=20,\n",
        "        min_count=2,\n",
        "        workers=10)\n",
        "firstModel.train(trainData, total_examples=len(trainData), epochs=10)\n",
        "\n",
        "print(len(list(firstModel.wv.vocab)))\n",
        "secondModel = gensim.models.Word2Vec(\n",
        "        trainData,\n",
        "        size=100,\n",
        "        window=1,\n",
        "        min_count=2,\n",
        "        workers=10)\n",
        "secondModel.train(trainData, total_examples=len(trainData), epochs=10)\n",
        "\n",
        "print(len(list(firstModel.wv.vocab)))\n",
        "thirdModel = gensim.models.Word2Vec(\n",
        "        trainData,\n",
        "        size=100,\n",
        "        window=10,\n",
        "        min_count=2,\n",
        "        workers=10)\n",
        "secondModel.train(trainData, total_examples=len(trainData), epochs=10)\n",
        "\n",
        "print(len(list(secondModel.wv.vocab)))\n",
        "\n",
        "firstModel.wv.save_word2vec_format(\"mydrive/My Drive/model_word2vec.kv\", binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8632\n",
            "8632\n",
            "8632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DKqXHUfWIo7p",
        "colab_type": "code",
        "outputId": "05c91f92-ac2a-4604-c806-a5aa26cc348e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2213
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Model with window 20 \\n\")\n",
        "listOfWords=firstModel.wv.index2word\n",
        "for i in range(10):\n",
        "  print(listOfWords[i])\n",
        "  print(firstModel.wv.most_similar(positive=listOfWords[i],topn=5))\n",
        "  print(\"\\n\")\n",
        "  \n",
        "\n",
        "  \n",
        "print(\"Model with window 1 \\n\")\n",
        "\n",
        "listOfWords2=secondModel.wv.index2word\n",
        "for i in range(10):\n",
        "  print(listOfWords2[i])\n",
        "  print(secondModel.wv.most_similar(positive=listOfWords2[i],topn=5))\n",
        "  print(\"\\n\")\n",
        "  \n",
        "print(\"Model with window 10 \\n\")\n",
        "listOfWords=firstModel.wv.index2word\n",
        "for i in range(10):\n",
        "  print(listOfWords[i])\n",
        "  print(thirdModel.wv.most_similar(positive=listOfWords[i],topn=5))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model with window 20 \n",
            "\n",
            "citation\n",
            "[('shown', 0.8754635453224182), ('mitchell', 0.823955774307251), ('lattices', 0.8055145740509033), ('scattering', 0.7792379260063171), ('snakes', 0.7704095244407654)]\n",
            "\n",
            "\n",
            "symbol\n",
            "[('conditional', 0.9454339742660522), ('th', 0.9439717531204224), ('sum', 0.9425514936447144), ('let', 0.9387654662132263), ('continuity', 0.9360517263412476)]\n",
            "\n",
            "\n",
            "number\n",
            "[('rt', 0.8805966973304749), ('ms', 0.8760619163513184), ('trial', 0.8758112192153931), ('inexperienced', 0.8743512630462646), ('accounted', 0.8671337366104126)]\n",
            "\n",
            "\n",
            "the\n",
            "[('it', 0.8811230659484863), ('this', 0.8800369501113892), ('step', 0.8741930723190308), ('kcal', 0.8636102676391602), ('symbolic', 0.8609758615493774)]\n",
            "\n",
            "\n",
            "in\n",
            "[('montanari', 0.9340759515762329), ('sdp', 0.9321562051773071), ('optimization', 0.9223915338516235), ('tree', 0.9219111800193787), ('laplacian', 0.9217284917831421)]\n",
            "\n",
            "\n",
            "model\n",
            "[('models', 0.855358898639679), ('undersampled', 0.7713569402694702), ('biophysically', 0.7413386702537537), ('descriptors', 0.7389814853668213), ('biomathematics', 0.727125883102417)]\n",
            "\n",
            "\n",
            "data\n",
            "[('bandwidth', 0.8696011900901794), ('walks', 0.8694165945053101), ('simultaneous', 0.8644351959228516), ('sets', 0.8517335653305054), ('unlabeled', 0.8511004447937012)]\n",
            "\n",
            "\n",
            "we\n",
            "[('our', 0.8645944595336914), ('interestingness', 0.8609367609024048), ('derive', 0.8334149718284607), ('allows', 0.8328555822372437), ('propose', 0.8092424869537354)]\n",
            "\n",
            "\n",
            "learning\n",
            "[('multi', 0.8984299898147583), ('concurrently', 0.8675034642219543), ('problems', 0.8593606948852539), ('standard', 0.8568105101585388), ('learn', 0.8555186986923218)]\n",
            "\n",
            "\n",
            "based\n",
            "[('predictions', 0.7964876890182495), ('models', 0.7896461486816406), ('statistical', 0.7848438024520874), ('hypotheses', 0.7807484865188599), ('use', 0.773299515247345)]\n",
            "\n",
            "\n",
            "Model with window 1 \n",
            "\n",
            "citation\n",
            "[('tversky', 0.6994071006774902), ('gigerenzer', 0.6961767673492432), ('navarrete', 0.6915862560272217), ('hsee', 0.6700218319892883), ('smith', 0.6616445183753967)]\n",
            "\n",
            "\n",
            "symbol\n",
            "[('arbitrary', 0.7766966819763184), ('denote', 0.7677399516105652), ('let', 0.7670567035675049), ('renewcommand', 0.7629221677780151), ('norm', 0.7610310316085815)]\n",
            "\n",
            "\n",
            "number\n",
            "[('ms', 0.7060928344726562), ('deaths', 0.6861369609832764), ('inexperienced', 0.6824749112129211), ('cooperating', 0.6661057472229004), ('replicates', 0.66573166847229)]\n",
            "\n",
            "\n",
            "the\n",
            "[('our', 0.766375720500946), ('thus', 0.6884056329727173), ('while', 0.6547149419784546), ('since', 0.650314450263977), ('moreover', 0.6291581988334656)]\n",
            "\n",
            "\n",
            "in\n",
            "[('special', 0.6618069410324097), ('subtraction', 0.6517200469970703), ('document', 0.6419464349746704), ('discussed', 0.6401288509368896), ('described', 0.6356357336044312)]\n",
            "\n",
            "\n",
            "model\n",
            "[('models', 0.6709046363830566), ('unavoidable', 0.6261441707611084), ('measures', 0.5917763113975525), ('concept', 0.5775974988937378), ('techniques', 0.5751166343688965)]\n",
            "\n",
            "\n",
            "data\n",
            "[('designs', 0.6215899586677551), ('datasets', 0.6120170950889587), ('examples', 0.5874627828598022), ('starting', 0.5845018625259399), ('verification', 0.5816606283187866)]\n",
            "\n",
            "\n",
            "we\n",
            "[('here', 0.8188572525978088), ('finally', 0.6103473901748657), ('netwalk', 0.5936444997787476), ('agi', 0.5833430290222168), ('informally', 0.5670108795166016)]\n",
            "\n",
            "\n",
            "learning\n",
            "[('turing', 0.787853479385376), ('semi', 0.7792571187019348), ('exploration', 0.7364593744277954), ('autonomous', 0.7305155992507935), ('operant', 0.703554630279541)]\n",
            "\n",
            "\n",
            "based\n",
            "[('aided', 0.6269758343696594), ('basis', 0.6269277334213257), ('uses', 0.6038698554039001), ('verifying', 0.6000784635543823), ('unified', 0.5710397958755493)]\n",
            "\n",
            "\n",
            "Model with window 10 \n",
            "\n",
            "citation\n",
            "[('making', 0.9910260438919067), ('decision', 0.9904265999794006), ('brandstatter', 0.9862481951713562), ('people', 0.9859484434127808), ('influencing', 0.9833326935768127)]\n",
            "\n",
            "\n",
            "symbol\n",
            "[('fig', 0.9752696752548218), ('denotes', 0.9742079973220825), ('denoted', 0.968928337097168), ('lookahead', 0.9287207126617432), ('v_k', 0.9164899587631226)]\n",
            "\n",
            "\n",
            "number\n",
            "[('percent', 0.9562860727310181), ('certificate', 0.9551335573196411), ('moderating', 0.9387713670730591), ('add', 0.9374567270278931), ('jellybeans', 0.9360558390617371)]\n",
            "\n",
            "\n",
            "the\n",
            "[('we', 0.9998765587806702), ('metric', 0.999703586101532), ('aixi', 0.9996787309646606), ('vector', 0.999674379825592), ('function', 0.9995946884155273)]\n",
            "\n",
            "\n",
            "in\n",
            "[('online', 0.9997169971466064), ('section', 0.9996894001960754), ('bandit', 0.9996670484542847), ('this', 0.9996140003204346), ('bounds', 0.9996034502983093)]\n",
            "\n",
            "\n",
            "model\n",
            "[('method', 0.999882161617279), ('structure', 0.9997861981391907), ('bayesian', 0.9997550845146179), ('gaussian', 0.999722957611084), ('general', 0.9997007846832275)]\n",
            "\n",
            "\n",
            "data\n",
            "[('this', 0.999576985836029), ('in', 0.9995431900024414), ('bounds', 0.9994808435440063), ('online', 0.9994691610336304), ('bandit', 0.9994301199913025)]\n",
            "\n",
            "\n",
            "we\n",
            "[('the', 0.9998765587806702), ('aixi', 0.999677836894989), ('metric', 0.9996470212936401), ('vector', 0.999577522277832), ('function', 0.9995431900024414)]\n",
            "\n",
            "\n",
            "learning\n",
            "[('algorithms', 0.9986547231674194), ('data', 0.9985414743423462), ('machine', 0.9984181523323059), ('regression', 0.9980831146240234), ('section', 0.9980629682540894)]\n",
            "\n",
            "\n",
            "based\n",
            "[('provide', 0.9998208284378052), ('including', 0.9997931718826294), ('developed', 0.9997903108596802), ('experimental', 0.9997705221176147), ('systems', 0.9997528791427612)]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yA3Y6lDcFg09",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For part 2 of the assignment we wanted to check the impact of different values in the window parametre for our word2vec model. So we created 3 model the first one had a window of size 20, the second one got a window of size 1 and the third one size of 10. We get the 5 more similar word for 10 specific words for every model. Some interesting results are the followings\n",
        "\n",
        "---\n",
        "Citation\n",
        "\n",
        "*   window 1 most common word: tversky(Name of scientist) \n",
        "\n",
        "*   Window 10 most common word: making\n",
        "\n",
        "*  Window 20 most common word: shown \n",
        "\n",
        "Learing\n",
        "\n",
        "*   window 1 most common word: turing\n",
        "\n",
        "*   Window 10 most common word: algorithms\n",
        "\n",
        "*  Window 20 most common word: multi \n",
        "\n",
        "A solid conclusion that we can draw is that window=1 is not enough. As for window 10 and 20 the word citation had a much better approach with the window=20, on the other hand the word learning got a better aproach with window=10. In general though we could say that higher window is better.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "1KR4_KCHsqw3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Part 3"
      ]
    },
    {
      "metadata": {
        "id": "Ze2N0S6BssH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path=\"mydrive/My Drive/labeled_articles/\"\n",
        "#load the files from the drive \n",
        "allFiles=[]\n",
        "#every element of list allFiles contains the same text 3 times from every evaluator\n",
        "for f in os.listdir(path):\n",
        "  new=True\n",
        "  for i in range(len(allFiles)):\n",
        "    if(allFiles[i][0][:-5]==f[:-5]):\n",
        "      new=False\n",
        "      allFiles[i].append(f)\n",
        "  if(new):\n",
        "    allFiles.append([f])\n",
        "X=[]\n",
        "Y=[]\n",
        "sentences=[]\n",
        "for i in range(len(allFiles)):\n",
        "  sentences=[]\n",
        "  for j in range(len(allFiles[i])):\n",
        "    sentences.append([])\n",
        "    filepath = path+allFiles[i][j]\n",
        "    with open(filepath) as fp:  \n",
        "      line = fp.readline()\n",
        "      while line:\n",
        "        sentences[j].append(line)\n",
        "        line = fp.readline()\n",
        "  #sentences contain 3 lists,every element of those lists contain a sentence from different evaluators\n",
        "  for k in range(len(sentences[0])):\n",
        "    #ignore comments\n",
        "    if(sentences[0][k][0]!='#'):\n",
        "      #for each sentence we extract the class from the 3 different evaluators\n",
        "      term1=sentences[0][k][:4]\n",
        "      term2=sentences[1][k][:4]\n",
        "      term3=sentences[2][k][:4]\n",
        "      #if 2 evaluators agree for the class of a sentence we accept it,otherwise we ignore the sentence\n",
        "      if(term1==term2 or term1==term3):\n",
        "        X.append(sentences[0][k][4:])\n",
        "        Y.append(term1)\n",
        "      elif(term2==term3):\n",
        "        X.append(sentences[0][k][4:])\n",
        "        Y.append(term2)\n",
        "X_preprossed=[]\n",
        "for sen in X:\n",
        "  sen=gensim.utils.simple_preprocess(remove_stopwords(sen))\n",
        "  fullSen=''\n",
        "  for i in range(len(sen)):\n",
        "    fullSen=fullSen+' ' + sen[i]\n",
        "  X_preprossed.append(fullSen)\n",
        "  \n",
        "  \n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(X_preprossed, Y, random_state = 22,stratify=Y)\n",
        "\n",
        "dictLabel={'AIMX':0,'OWNX':1,'CONT':4,'BASE':3,'MISC':2}\n",
        "\n",
        "Ytrain=[dictLabel[label] for label in y_train]\n",
        "\n",
        "# create the tokenizer\n",
        "tokenizerTrain = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "tokenizerTrain.fit_on_texts(x_train)\n",
        "\n",
        "max_length = max([len(s.split()) for s in x_train])\n",
        "\n",
        "encoded_docsTrain = tokenizerTrain.texts_to_sequences(x_train)\n",
        "# pad sequences\n",
        "Xtrain = pad_sequences(encoded_docsTrain, maxlen=max_length, padding='post')\n",
        "#print(Xtrain)\n",
        "vocab_size = len(tokenizerTrain.word_index) + 1\n",
        "\n",
        "Ytest=[dictLabel[label] for label in y_test]\n",
        "\n",
        "\n",
        "# create the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "tokenizer.fit_on_texts(x_test)\n",
        "\n",
        "encoded_docs = tokenizer.texts_to_sequences(x_test)\n",
        "# pad sequences\n",
        "Xtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "#print(Xtrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CCD6IzXNAeI8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "from numpy import sum as sumarray\n",
        "def calculateMetrics(predictions,reals,classesLength):\n",
        "  falsePositives = [0] * classesLength\n",
        "  truePositives = [0] * classesLength\n",
        "  falseNegatives = [0] * classesLength\n",
        "  for i in range(len(reals)):\n",
        "    myPred = argmax(predictions[i])\n",
        "    real = reals[i]\n",
        "    if myPred==real:\n",
        "      truePositives[real] += 1\n",
        "    else:\n",
        "      falsePositives[myPred]+=1\n",
        "      falseNegatives[real]+=1\n",
        "  precision=(sumarray(truePositives)/(sumarray(truePositives)+sumarray(falsePositives)))/classesLength\n",
        "  recall = (sumarray(truePositives)/(sumarray(truePositives)+sumarray(falseNegatives)))/classesLength\n",
        "  f1 = 2*precision*recall/(precision+recall)\n",
        "  return precision,recall,f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YRXoGbF-s1GD",
        "colab_type": "code",
        "outputId": "65eca628-58a8-4bc8-a908-42b1d016ba3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(Lambda(lambda x: sum(x, axis=1)))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "predicts=model.predict(Xtest)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_58 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "lambda_57 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            " - 3s - loss: 1.3610 - acc: 0.5052\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.0193 - acc: 0.6418\n",
            "Epoch 3/10\n",
            " - 0s - loss: 0.9509 - acc: 0.6057\n",
            "Epoch 4/10\n",
            " - 0s - loss: 0.8400 - acc: 0.6044\n",
            "Epoch 5/10\n",
            " - 0s - loss: 0.7016 - acc: 0.6044\n",
            "Epoch 6/10\n",
            " - 0s - loss: 0.5649 - acc: 0.6057\n",
            "Epoch 7/10\n",
            " - 0s - loss: 0.4985 - acc: 0.6070\n",
            "Epoch 8/10\n",
            " - 0s - loss: 0.4520 - acc: 0.6108\n",
            "Epoch 9/10\n",
            " - 0s - loss: 0.4210 - acc: 0.6198\n",
            "Epoch 10/10\n",
            " - 0s - loss: 0.3559 - acc: 0.7809\n",
            "Test Accuracy: 55.984556\n",
            "Precision =  0.11196911196911197 \n",
            " Recall =  0.11196911196911197 \n",
            "F1 =  0.11196911196911197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q8SZS4yZOR1T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From  the results of this model we understand we overfit the model we need to add new layers to stop it"
      ]
    },
    {
      "metadata": {
        "id": "X6rdTid8OkSA",
        "colab_type": "code",
        "outputId": "0cb0fe15-ca61-4c22-c0de-3adb00ccbdaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(Dropout(0.9))\n",
        "model.add(Lambda(lambda x: sum(x, axis=1)))\n",
        "model.add(Dropout(0.9))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "# compile network\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "predicts=model.predict(Xtest)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_59 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 66, 100)           0         \n",
            "_________________________________________________________________\n",
            "lambda_58 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            " - 3s - loss: 2.5981 - acc: 0.3582\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.7326 - acc: 0.4291\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.5958 - acc: 0.4446\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.5152 - acc: 0.4381\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.4363 - acc: 0.4704\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.3746 - acc: 0.4523\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.2813 - acc: 0.4961\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.3424 - acc: 0.4897\n",
            "Epoch 9/10\n",
            " - 0s - loss: 1.3017 - acc: 0.5284\n",
            "Epoch 10/10\n",
            " - 0s - loss: 1.2984 - acc: 0.5322\n",
            "Test Accuracy: 60.231660\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sqdKROoQO8Td",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding a Dropout layers with dropout ration 0.7 we prevent overfitting for 10 epochs and we get the expecting results"
      ]
    },
    {
      "metadata": {
        "id": "7U4BZUbWwoup",
        "colab_type": "code",
        "outputId": "bf6d699c-b65f-4e80-c642-56c3b6d16a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(vocab_size,max_length)\n",
        "print(Xtrain.shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(Lambda(lambda x: sum(x, axis=1)))\n",
        "model.add(Dropout(0.75))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dropout(0.75))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "predicts=model.predict(Xtest)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3323 66\n",
            "(776, 66)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_29 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "lambda_29 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 16)                1616      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 5)                 85        \n",
            "=================================================================\n",
            "Total params: 334,001\n",
            "Trainable params: 334,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            " - 2s - loss: 4.1163 - acc: 0.3209\n",
            "Epoch 2/10\n",
            " - 0s - loss: 2.1576 - acc: 0.4549\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.8757 - acc: 0.5039\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.6149 - acc: 0.5683\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.5640 - acc: 0.5580\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.4698 - acc: 0.5812\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.4265 - acc: 0.5863\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.4473 - acc: 0.5786\n",
            "Epoch 9/10\n",
            " - 0s - loss: 1.3939 - acc: 0.5825\n",
            "Epoch 10/10\n",
            " - 0s - loss: 1.3899 - acc: 0.5902\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R-RdssSnQfFI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding one more dence layer doesn't improve the results and have a toll in execution time and more dropout layers are needed to prevent overfitting"
      ]
    },
    {
      "metadata": {
        "id": "0yMVVEELfdKv",
        "colab_type": "code",
        "outputId": "87781c19-f713-4a14-c97a-a521fb9e223b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "predicts=model.predict(Xtest)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_31 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "lambda_31 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            " - 2s - loss: 1.5607 - acc: 0.6044\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.4607 - acc: 0.6044\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.3401 - acc: 0.6044\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.2093 - acc: 0.6044\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.1067 - acc: 0.6044\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.0482 - acc: 0.6044\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.0196 - acc: 0.6044\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.0046 - acc: 0.6044\n",
            "Epoch 9/10\n",
            " - 0s - loss: 0.9963 - acc: 0.6044\n",
            "Epoch 10/10\n",
            " - 0s - loss: 0.9898 - acc: 0.6044\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SF4JlOOhRL1C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using average instead of sum prevents overfitting without the need of dropout layers"
      ]
    },
    {
      "metadata": {
        "id": "RvgvQG78gbj9",
        "colab_type": "code",
        "outputId": "4986f690-74e3-41ba-f550-1218d622a572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2125
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "  #model.add(Flatten())\n",
        "  model.add(Dense(5, activation='linear'))\n",
        "  print(model.summary())\n",
        "  # compile network\n",
        "  from keras import optimizers\n",
        "\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  model.fit(Xtrain, Ytrain, epochs=5, verbose=2)\n",
        "  predicts=model.predict(Xtest)\n",
        "  # evaluate\n",
        "  loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "  print('Test Accuracy: %f' % (acc*100))\n",
        "  precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "  print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 66, 100)           0         \n",
            "_________________________________________________________________\n",
            "lambda_32 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 2.4879 - acc: 0.1430\n",
            "Epoch 2/5\n",
            " - 0s - loss: 1.6094 - acc: 0.1585\n",
            "Epoch 3/5\n",
            " - 0s - loss: 1.6077 - acc: 0.2564\n",
            "Epoch 4/5\n",
            " - 0s - loss: 1.6181 - acc: 0.2216\n",
            "Epoch 5/5\n",
            " - 0s - loss: 1.6094 - acc: 0.0554\n",
            "Test Accuracy: 5.791506\n",
            "0\n",
            "Precision =  0.011583011583011584 \n",
            " Recall =  0.011583011583011584 \n",
            "F1 =  0.011583011583011584\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_33 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 66, 100)           0         \n",
            "_________________________________________________________________\n",
            "lambda_33 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 2.4208 - acc: 0.2513\n",
            "Epoch 2/5\n",
            " - 0s - loss: 1.6094 - acc: 0.3505\n",
            "Epoch 3/5\n",
            " - 0s - loss: 1.6094 - acc: 0.3647\n",
            "Epoch 4/5\n",
            " - 0s - loss: 1.6094 - acc: 0.3802\n",
            "Epoch 5/5\n",
            " - 0s - loss: 1.6094 - acc: 0.3492\n",
            "Test Accuracy: 29.343629\n",
            "166\n",
            "Precision =  0.058687258687258693 \n",
            " Recall =  0.058687258687258693 \n",
            "F1 =  0.058687258687258693\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_34 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 66, 100)           0         \n",
            "_________________________________________________________________\n",
            "lambda_34 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 4.3350 - acc: 0.1804\n",
            "Epoch 2/5\n",
            " - 0s - loss: 1.6074 - acc: 0.3273\n",
            "Epoch 3/5\n",
            " - 0s - loss: 1.6074 - acc: 0.3879\n",
            "Epoch 4/5\n",
            " - 0s - loss: 1.6074 - acc: 0.4201\n",
            "Epoch 5/5\n",
            " - 0s - loss: 1.6189 - acc: 0.5399\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_35 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 66, 100)           0         \n",
            "_________________________________________________________________\n",
            "lambda_35 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 2.5297 - acc: 0.4704\n",
            "Epoch 2/5\n",
            " - 0s - loss: 1.8817 - acc: 0.6044\n",
            "Epoch 3/5\n",
            " - 0s - loss: 1.7538 - acc: 0.6082\n",
            "Epoch 4/5\n",
            " - 0s - loss: 1.5827 - acc: 0.6121\n",
            "Epoch 5/5\n",
            " - 0s - loss: 1.3335 - acc: 0.6804\n",
            "Test Accuracy: 59.459459\n",
            "15\n",
            "Precision =  0.11891891891891893 \n",
            " Recall =  0.11891891891891893 \n",
            "F1 =  0.11891891891891893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ktd0jwGkRqri",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using as an activation function the linear function we get a big range of different scores from 5% up to 12% thats is the score that we actually achieve"
      ]
    },
    {
      "metadata": {
        "id": "SvqATud3izu0",
        "colab_type": "code",
        "outputId": "63349328-5a18-4579-9fed-03763903feb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "predicts=model.predict(Xtest)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_37 (Embedding)     (None, 66, 100)           332300    \n",
            "_________________________________________________________________\n",
            "lambda_37 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 332,805\n",
            "Trainable params: 332,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            " - 2s - loss: 1.5235 - acc: 0.4923\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.3466 - acc: 0.6044\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.1794 - acc: 0.6044\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.0654 - acc: 0.6044\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.0176 - acc: 0.6044\n",
            "Epoch 6/10\n",
            " - 0s - loss: 0.9992 - acc: 0.6044\n",
            "Epoch 7/10\n",
            " - 0s - loss: 0.9864 - acc: 0.6044\n",
            "Epoch 8/10\n",
            " - 0s - loss: 0.9734 - acc: 0.6044\n",
            "Epoch 9/10\n",
            " - 0s - loss: 0.9596 - acc: 0.6044\n",
            "Epoch 10/10\n",
            " - 0s - loss: 0.9444 - acc: 0.6044\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVvv32NiSTlN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the softmax activation function we get similar results as the sigmoid activation function"
      ]
    },
    {
      "metadata": {
        "id": "DarHzjlQ5H8z",
        "colab_type": "code",
        "outputId": "0cf3c6c1-2b02-476e-aef6-b3d2e32ba828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "cell_type": "code",
      "source": [
        "print(max_length)\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(firstModel.wv.get_keras_embedding(train_embeddings=True))\n",
        "model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(\"\\nModel Summary:\\n\", model.summary())\n",
        "\n",
        "           \n",
        "# compile network\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_39 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_39 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 863,705\n",
            "Trainable params: 863,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/10\n",
            " - 2s - loss: 1.7732 - acc: 0.6031\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.1071 - acc: 0.6031\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.0321 - acc: 0.6031\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.0298 - acc: 0.6031\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.0265 - acc: 0.6031\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.0234 - acc: 0.6031\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.0192 - acc: 0.6044\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.0163 - acc: 0.6044\n",
            "Epoch 9/10\n",
            " - 0s - loss: 1.0125 - acc: 0.6044\n",
            "Epoch 10/10\n",
            " - 0s - loss: 1.0100 - acc: 0.6044\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IIx67cdcSj-P",
        "colab_type": "code",
        "outputId": "4e0da83e-e0e0-4ec8-b3ec-445a4a2f577c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(firstModel.wv.get_keras_embedding(train_embeddings=True))\n",
        "model.add(Lambda(lambda x: sum(x, axis=1)))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(\"\\nModel Summary:\\n\", model.summary())\n",
        "\n",
        "           \n",
        "# compile network\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_42 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_42 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 863,705\n",
            "Trainable params: 863,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/10\n",
            " - 2s - loss: 9.6157 - acc: 0.0438\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.6281 - acc: 0.0631\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.6281 - acc: 0.0657\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.6281 - acc: 0.0606\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.6121 - acc: 0.0554\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.6094 - acc: 0.0554\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.6094 - acc: 0.0554\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.6094 - acc: 0.0554\n",
            "Epoch 9/10\n",
            " - 0s - loss: 1.6094 - acc: 0.0554\n",
            "Epoch 10/10\n",
            " - 0s - loss: 1.6094 - acc: 0.0554\n",
            "Test Accuracy: 5.405405\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RyYi_QkjSkQL",
        "colab_type": "code",
        "outputId": "9e600956-314d-47bd-cbc3-0526256b66bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2125
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "# define model\n",
        "  model = Sequential()\n",
        "  model.add(firstModel.wv.get_keras_embedding(train_embeddings=False))\n",
        "  model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "  model.add(Dense(5, activation='linear'))\n",
        "  print(\"\\nModel Summary:\\n\", model.summary())\n",
        "\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  model.fit(Xtrain, Ytrain, epochs=5, verbose=2)\n",
        "  # evaluate\n",
        "  loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "  print('Test Accuracy: %f' % (acc*100))\n",
        "  precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "  print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_44 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_43 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 863,705\n",
            "Trainable params: 505\n",
            "Non-trainable params: 863,200\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 1.5627 - acc: 0.0606\n",
            "Epoch 2/5\n",
            " - 0s - loss: 1.5437 - acc: 0.0619\n",
            "Epoch 3/5\n",
            " - 0s - loss: 1.5517 - acc: 0.0619\n",
            "Epoch 4/5\n",
            " - 0s - loss: 1.5487 - acc: 0.0619\n",
            "Epoch 5/5\n",
            " - 0s - loss: 1.5448 - acc: 0.0619\n",
            "Test Accuracy: 6.177606\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_45 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_44 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 863,705\n",
            "Trainable params: 505\n",
            "Non-trainable params: 863,200\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 6.2165 - acc: 0.5979\n",
            "Epoch 2/5\n",
            " - 0s - loss: 6.0387 - acc: 0.6031\n",
            "Epoch 3/5\n",
            " - 0s - loss: 5.8742 - acc: 0.6031\n",
            "Epoch 4/5\n",
            " - 0s - loss: 5.7823 - acc: 0.6031\n",
            "Epoch 5/5\n",
            " - 0s - loss: 5.9902 - acc: 0.5657\n",
            "Test Accuracy: 46.718147\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_46 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_45 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 863,705\n",
            "Trainable params: 505\n",
            "Non-trainable params: 863,200\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 10.8461 - acc: 0.0168\n",
            "Epoch 2/5\n",
            " - 0s - loss: 1.6386 - acc: 0.0232\n",
            "Epoch 3/5\n",
            " - 0s - loss: 1.6207 - acc: 0.0219\n",
            "Epoch 4/5\n",
            " - 0s - loss: 1.6062 - acc: 0.0180\n",
            "Epoch 5/5\n",
            " - 0s - loss: 1.6062 - acc: 0.0155\n",
            "Test Accuracy: 3.088803\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_47 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_46 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 863,705\n",
            "Trainable params: 505\n",
            "Non-trainable params: 863,200\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/5\n",
            " - 2s - loss: 2.4552 - acc: 0.6005\n",
            "Epoch 2/5\n",
            " - 0s - loss: 2.5450 - acc: 0.6031\n",
            "Epoch 3/5\n",
            " - 0s - loss: 2.5367 - acc: 0.6031\n",
            "Epoch 4/5\n",
            " - 0s - loss: 2.4918 - acc: 0.5812\n",
            "Epoch 5/5\n",
            " - 0s - loss: 2.4716 - acc: 0.6031\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vgT8uuAES94C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the linear activation function for the pretrained Embedding gives as consistently f1 score equals to 12%."
      ]
    },
    {
      "metadata": {
        "id": "rIL2Mq3rSka5",
        "colab_type": "code",
        "outputId": "fc970f93-cee4-4f54-fb1a-00dc4837e057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(firstModel.wv.get_keras_embedding(train_embeddings=True))\n",
        "model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(\"\\nModel Summary:\\n\", model.summary())\n",
        "\n",
        "           \n",
        "# compile network\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_49 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_48 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 32)                3232      \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 5)                 85        \n",
            "=================================================================\n",
            "Total params: 867,045\n",
            "Trainable params: 867,045\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/10\n",
            " - 3s - loss: 1.5336 - acc: 0.4884\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.3607 - acc: 0.6031\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.2915 - acc: 0.6031\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.2114 - acc: 0.6044\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.0614 - acc: 0.6044\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.0362 - acc: 0.6044\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.0352 - acc: 0.6044\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.0356 - acc: 0.6044\n",
            "Epoch 9/10\n",
            " - 0s - loss: 1.0220 - acc: 0.6044\n",
            "Epoch 10/10\n",
            " - 0s - loss: 1.0251 - acc: 0.6044\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wQBMXVCK4Dc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding more dence layers still doesn't improve the f1 score"
      ]
    },
    {
      "metadata": {
        "id": "lYvddiO1pn8a",
        "colab_type": "code",
        "outputId": "f9ecb69c-3017-4876-e4bb-b805f1f6fee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(firstModel.wv.get_keras_embedding(train_embeddings=False))\n",
        "model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(\"\\nModel Summary:\\n\", model.summary())\n",
        "\n",
        "           \n",
        "# compile network\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_50 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "lambda_49 (Lambda)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 863,705\n",
            "Trainable params: 505\n",
            "Non-trainable params: 863,200\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/10\n",
            " - 2s - loss: 1.3478 - acc: 0.3222\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.1350 - acc: 0.6031\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.0370 - acc: 0.6031\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.0310 - acc: 0.6031\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.0298 - acc: 0.6031\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.0274 - acc: 0.6031\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.0276 - acc: 0.6044\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.0272 - acc: 0.6044\n",
            "Epoch 9/10\n",
            " - 0s - loss: 1.0269 - acc: 0.6044\n",
            "Epoch 10/10\n",
            " - 0s - loss: 1.0252 - acc: 0.6044\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t0aterOaNkk8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By setting the trainable parametre False we get the same f1 score with much faster execution time"
      ]
    },
    {
      "metadata": {
        "id": "4ioEmIn8O2kO",
        "colab_type": "code",
        "outputId": "93b141cf-397c-4432-d18d-bacfc02696f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(firstModel.wv.get_keras_embedding(train_embeddings=True))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', data_format='channels_first'))\n",
        "model.add(Lambda(lambda x: mean(x, axis=1)))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "print(\"\\nModel Summary:\\n\", model.summary())\n",
        "\n",
        "           \n",
        "# compile network\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "precision,recall,f1 = calculateMetrics(predicts,Ytest,len(dictLabel))\n",
        "print(\"Precision = \",precision,\"\\n Recall = \",recall,\"\\nF1 = \",f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_54 (Embedding)     (None, None, 100)         863200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, None, 50)          0         \n",
            "_________________________________________________________________\n",
            "lambda_53 (Lambda)           (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 5)                 255       \n",
            "=================================================================\n",
            "Total params: 863,455\n",
            "Trainable params: 863,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model Summary:\n",
            " None\n",
            "Epoch 1/10\n",
            " - 3s - loss: 1.5185 - acc: 0.5979\n",
            "Epoch 2/10\n",
            " - 1s - loss: 1.1157 - acc: 0.6044\n",
            "Epoch 3/10\n",
            " - 1s - loss: 1.0318 - acc: 0.6044\n",
            "Epoch 4/10\n",
            " - 1s - loss: 1.0220 - acc: 0.6044\n",
            "Epoch 5/10\n",
            " - 1s - loss: 1.0199 - acc: 0.6044\n",
            "Epoch 6/10\n",
            " - 1s - loss: 1.0182 - acc: 0.6044\n",
            "Epoch 7/10\n",
            " - 1s - loss: 1.0156 - acc: 0.6044\n",
            "Epoch 8/10\n",
            " - 1s - loss: 1.0127 - acc: 0.6044\n",
            "Epoch 9/10\n",
            " - 1s - loss: 1.0105 - acc: 0.6044\n",
            "Epoch 10/10\n",
            " - 1s - loss: 1.0084 - acc: 0.6044\n",
            "Test Accuracy: 60.231660\n",
            "0\n",
            "Precision =  0.12046332046332046 \n",
            " Recall =  0.12046332046332046 \n",
            "F1 =  0.12046332046332046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NmfmPv3oPQ0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pooling doesn't improve the results either."
      ]
    },
    {
      "metadata": {
        "id": "mjSnK44VPdjN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "General observations\n",
        "\n",
        "For most of our experiments the results were consistant and the f1 score never surpassed the 12%. Only exception was the linear activation function. The amount of data was not big enough to be able to increase f1 score."
      ]
    }
  ]
}